{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6899627",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/FAC/FGSE/IDYST/tbeucler/default/saranya/miniconda3/envs/unil_tigramite/lib/python3.8/site-packages/tigramite/models.py:29: UserWarning: [Errno 2] No such file or directory: '/work/FAC/FGSE/IDYST/tbeucler/default/saranya/miniconda3/envs/unil_tigramite/lib/python3.8/site-packages/tigramite/../versions.py'\n",
      "  warnings.warn(str(e))\n",
      "/work/FAC/FGSE/IDYST/tbeucler/default/saranya/miniconda3/envs/unil_tigramite/lib/python3.8/site-packages/tigramite/plotting.py:26: UserWarning: [Errno 2] No such file or directory: '/work/FAC/FGSE/IDYST/tbeucler/default/saranya/miniconda3/envs/unil_tigramite/lib/python3.8/site-packages/tigramite/../versions.py'\n",
      "  warnings.warn(str(e))\n",
      "/work/FAC/FGSE/IDYST/tbeucler/default/saranya/miniconda3/envs/unil_tigramite/lib/python3.8/site-packages/tigramite/independence_tests/gpdc.py:27: UserWarning: [Errno 2] No such file or directory: '/work/FAC/FGSE/IDYST/tbeucler/default/saranya/miniconda3/envs/unil_tigramite/lib/python3.8/site-packages/tigramite/independence_tests/../../versions.py'\n",
      "  warnings.warn(str(e))\n",
      "/work/FAC/FGSE/IDYST/tbeucler/default/saranya/miniconda3/envs/unil_tigramite/lib/python3.8/site-packages/tigramite/independence_tests/gpdc_torch.py:33: UserWarning: [Errno 2] No such file or directory: '/work/FAC/FGSE/IDYST/tbeucler/default/saranya/miniconda3/envs/unil_tigramite/lib/python3.8/site-packages/tigramite/independence_tests/../../versions.py'\n",
      "  warnings.warn(str(e))\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline     \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob,os\n",
    "from tqdm.auto import tqdm\n",
    "import math\n",
    "import sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "import tigramite\n",
    "from tigramite import data_processing as pp\n",
    "from tigramite.toymodels import structural_causal_processes as toys\n",
    "from tigramite.models import Models, Prediction\n",
    "from tigramite import plotting as tp\n",
    "from tigramite.pcmci import PCMCI\n",
    "from tigramite.independence_tests import ParCorr, GPDC, CMIknn, CMIsymb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eef97686",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_links(tau_min, tau_max, parents, children):\n",
    "    \"\"\"\n",
    "    This function selects the causal links that will be tested by\n",
    "    PCMCI. The links are selected such that per each variable in\n",
    "    `children` all `parents` are stablished as causes, and no other\n",
    "    causal relationships exist.\n",
    "    \n",
    "    Assumes `parents` and `children` are disjoint sets, and that all\n",
    "    variables are included in the union of both sets.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    tau_min : int\n",
    "        Minimum time lag to test. Note that zero-lags are undirected.\n",
    "    tau_max : int\n",
    "        Maximum time lag. Must be larger or equal to tau_min.\n",
    "    parents : set of int\n",
    "        List of variables that will be assigned as a parent link.\n",
    "        Assumed to be disjoint with children\n",
    "    children : set of int\n",
    "        List of variables that will be assigned a link from a parent.\n",
    "        Assumed to be disjoint with parents\n",
    "    Returns\n",
    "    -------\n",
    "    selected_links: dict\n",
    "        Dictionary of selected links for Tigramite\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    parents = set(parents)\n",
    "    children = set(children)\n",
    "\n",
    "    selected_links = dict()\n",
    "    # Set the default as all combinations of the selected variables\n",
    "    for var in [*children, *parents]:\n",
    "        if var in children:\n",
    "            # Children can be caused only by parents and by themselves\n",
    "            selected_links[var] = [\n",
    "                (parent, -lag)\n",
    "                for parent in parents\n",
    "                for lag in range(tau_min, tau_max + 1)\n",
    "            ]\n",
    "        else:\n",
    "            selected_links[var] = []\n",
    "\n",
    "    return selected_links\n",
    "\n",
    "def _process_dataset(path=None):\n",
    "    df1 = pd.read_csv(path,sep=',')\n",
    "    df1.rename({\"Unnamed: 0\":\"a\"}, axis=\"columns\", inplace=True)\n",
    "    df1=df1.drop('a', axis=1)\n",
    "    df1=df1.drop('conv_rrate', axis=1)\n",
    "    df1=df1.drop('ls_rrate', axis=1)\n",
    "    df1=df1.drop('mn_conv_prate', axis=1)\n",
    "    df1=df1.drop('mn_ls_prate', axis=1)\n",
    "    df1=df1.drop('mn_tot_prate', axis=1)\n",
    "    df1=df1.drop('outconv_rrate', axis=1)\n",
    "    df1=df1.drop('outls_rrate', axis=1)\n",
    "    df1=df1.drop('outmn_conv_prate', axis=1)\n",
    "    df1=df1.drop('outmn_ls_prate', axis=1)\n",
    "    df1=df1.drop('outmn_tot_prate', axis=1)\n",
    "    df1=df1.drop('conv_ppt', axis=1)\n",
    "    df1=df1.drop('outconv_ppt', axis=1)\n",
    "    \n",
    "    TCname = path.split('/')[-1].split('.')[0].split('_')[-1]\n",
    "    #print(TCname)\n",
    "    for item in glob.glob('/work/FAC/FGSE/IDYST/tbeucler/default/saranya/causal/targets/*tot_ppt_int*'):\n",
    "        if str(TCname) in item:\n",
    "            d1=pd.read_csv(item)\n",
    "            d1.rename({\"Unnamed: 0\":\"a\"}, axis=\"columns\", inplace=True)\n",
    "            d1=d1.drop('a', axis=1)\n",
    "            dt1=pd.concat([d1,df1],axis=1, join='inner')\n",
    "        else:\n",
    "            continue\n",
    "    return dt1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "255b15ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "p1=\"../../timeseries_csv/ts_wp/\"\n",
    "p2=\"../../timeseries_csv/ts_nio/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a8fec9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds1=_process_dataset(glob.glob(p1+'*2020vongfong*')[0])\n",
    "ds2=_process_dataset(glob.glob(p1+'*2020chanhom*')[0])\n",
    "ds3=_process_dataset(glob.glob(p1+'*2020saudel*')[0])\n",
    "ds4=_process_dataset(glob.glob(p1+'*2020molave*')[0])\n",
    "ds5=_process_dataset(glob.glob(p1+'*2020goni*')[0])\n",
    "ds6=_process_dataset(glob.glob(p1+'*2020atsani*')[0])\n",
    "ds7=_process_dataset(glob.glob(p1+'*2020vamco*')[0])\n",
    "ds8=_process_dataset(glob.glob(p1+'*2019neoguri*')[0])\n",
    "ds9=_process_dataset(glob.glob(p1+'*2019bualoi*')[0])\n",
    "ds10=_process_dataset(glob.glob(p1+'*2019halong*')[0])\n",
    "ds11=_process_dataset(glob.glob(p1+'*2019nakri*')[0])\n",
    "ds12=_process_dataset(glob.glob(p1+'*2019fengshen*')[0])\n",
    "ds13=_process_dataset(glob.glob(p1+'*2019kalmaegi*')[0])\n",
    "ds14=_process_dataset(glob.glob(p1+'*2019fungwong*')[0])\n",
    "ds15=_process_dataset(glob.glob(p1+'*2019kammuri*')[0])\n",
    "ds16=_process_dataset(glob.glob(p1+'*2018jelawat*')[0])\n",
    "ds17=_process_dataset(glob.glob(p1+'*2018maliksi*')[0])\n",
    "ds18=_process_dataset(glob.glob(p1+'*2018kongrey*')[0])\n",
    "ds19=_process_dataset(glob.glob(p1+'*2018yutu*')[0])\n",
    "ds20=_process_dataset(glob.glob(p1+'*2017muifa*')[0])\n",
    "ds21=_process_dataset(glob.glob(p1+'*2017lan*')[0])\n",
    "ds22=_process_dataset(glob.glob(p1+'*2017haikul*')[0])\n",
    "ds23=_process_dataset(glob.glob(p1+'*2016megi*')[0])\n",
    "ds24=_process_dataset(glob.glob(p1+'*2016sarika*')[0])\n",
    "ds25=_process_dataset(glob.glob(p1+'*2016haima*')[0])\n",
    "ds26=_process_dataset(glob.glob(p1+'*2015maysak*')[0])\n",
    "ds27=_process_dataset(glob.glob(p1+'*2015koppu*')[0])\n",
    "ds28=_process_dataset(glob.glob(p1+'*2015infa*')[0])\n",
    "ds29=_process_dataset(glob.glob(p1+'*2014tapah*')[0])\n",
    "ds30=_process_dataset(glob.glob(p1+'*2014nuri*')[0])\n",
    "ds31=_process_dataset(glob.glob(p1+'*2014hagupit*')[0])\n",
    "ds32=_process_dataset(glob.glob(p1+'*2013yagi*')[0])\n",
    "ds33=_process_dataset(glob.glob(p1+'*2013fitow*')[0])\n",
    "ds34=_process_dataset(glob.glob(p1+'*2013danas*')[0])\n",
    "ds35=_process_dataset(glob.glob(p1+'*2013francisco*')[0])\n",
    "ds36=_process_dataset(glob.glob(p1+'*2013krosa*')[0])\n",
    "ds37=_process_dataset(glob.glob(p1+'*2013haiyan*')[0])\n",
    "ds38=_process_dataset(glob.glob(p1+'*2012guchol*')[0])\n",
    "ds39=_process_dataset(glob.glob(p1+'*2012gaemi*')[0])\n",
    "ds40=_process_dataset(glob.glob(p1+'*2012maria*')[0])\n",
    "ds41=_process_dataset(glob.glob(p1+'*2012sontinh*')[0])\n",
    "ds42=_process_dataset(glob.glob(p1+'*2012bopha*')[0])\n",
    "ds43=_process_dataset(glob.glob(p1+'*2011songda*')[0])\n",
    "ds44=_process_dataset(glob.glob(p1+'*2011haima*')[0])\n",
    "ds45=_process_dataset(glob.glob(p1+'*2011nalgae*')[0])\n",
    "ds46=_process_dataset(glob.glob(p1+'*2011washi*')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1d915f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds47=_process_dataset(glob.glob(p1+'*2010OMAIS*')[0])\n",
    "ds48=_process_dataset(glob.glob(p1+'*2010CONSON*')[0])\n",
    "ds49=_process_dataset(glob.glob(p1+'*2010CHANTHU*')[0])\n",
    "ds50=_process_dataset(glob.glob(p1+'*2010DIANMU*')[0])\n",
    "ds51=_process_dataset(glob.glob(p1+'*2010LIONROCK*')[0])\n",
    "ds52=_process_dataset(glob.glob(p1+'*2010MALOU*')[0])\n",
    "ds53=_process_dataset(glob.glob(p1+'*2010FANAPI*')[0])\n",
    "ds54=_process_dataset(glob.glob(p1+'*2010MALAKAS*')[0])\n",
    "ds55=_process_dataset(glob.glob(p1+'*2010MEGI*')[0])\n",
    "ds56=_process_dataset(glob.glob(p1+'*2010CHABA*')[0])\n",
    "ds57=_process_dataset(glob.glob(p1+'*2010OMEKA*')[0])\n",
    "ds58=_process_dataset(glob.glob(p1+'*2009KUJIRA*')[0])\n",
    "ds59=_process_dataset(glob.glob(p1+'*2009CHAN-HOM*')[0])\n",
    "ds60=_process_dataset(glob.glob(p1+'*2009LINFA*')[0])\n",
    "ds61=_process_dataset(glob.glob(p1+'*2009MORAKOT*')[0])\n",
    "ds62=_process_dataset(glob.glob(p1+'*2009ETAU*')[0])\n",
    "ds63=_process_dataset(glob.glob(p1+'*2009VAMCO*')[0])\n",
    "ds64=_process_dataset(glob.glob(p1+'*2009KROVANH*')[0])\n",
    "ds65=_process_dataset(glob.glob(p1+'*2009DUJUAN*')[0])\n",
    "ds66=_process_dataset(glob.glob(p1+'*2009CHOI-WAN*')[0])\n",
    "ds67=_process_dataset(glob.glob(p1+'*2009PARMA*')[0])\n",
    "ds68=_process_dataset(glob.glob(p1+'*2009MELOR*')[0])\n",
    "ds69=_process_dataset(glob.glob(p1+'*2009LUPIT*')[0])\n",
    "ds70=_process_dataset(glob.glob(p1+'*2009MIRINAE*')[0])\n",
    "ds71=_process_dataset(glob.glob(p1+'*2009NIDA*')[0])\n",
    "ds72=_process_dataset(glob.glob(p1+'*2008NEOGURI*')[0])\n",
    "ds73=_process_dataset(glob.glob(p1+'*2008RAMMASUN*')[0])\n",
    "ds74=_process_dataset(glob.glob(p1+'*2008NAKRI*')[0])\n",
    "ds75=_process_dataset(glob.glob(p1+'*2008FENGSHEN*')[0])\n",
    "ds76=_process_dataset(glob.glob(p1+'*2008KALMAEGI*')[0])\n",
    "ds77=_process_dataset(glob.glob(p1+'*2008FUNG-WONG*')[0])\n",
    "ds78=_process_dataset(glob.glob(p1+'*2008VONGFONG*')[0])\n",
    "ds79=_process_dataset(glob.glob(p1+'*2008NURI*')[0])\n",
    "ds80=_process_dataset(glob.glob(p1+'*2008SINLAKU*')[0])\n",
    "ds81=_process_dataset(glob.glob(p1+'*2008HAGUPIT*')[0])\n",
    "ds82=_process_dataset(glob.glob(p1+'*2008JANGMI*')[0])\n",
    "ds83=_process_dataset(glob.glob(p1+'*2008HIGOS*')[0])\n",
    "ds84=_process_dataset(glob.glob(p1+'*2008MAYSAK*')[0])\n",
    "ds85=_process_dataset(glob.glob(p1+'*2008DOLPHIN*')[0])\n",
    "ds86=_process_dataset(glob.glob(p1+'*2007KONG-REY*')[0])\n",
    "ds87=_process_dataset(glob.glob(p1+'*2007MAN-YI*')[0])\n",
    "ds88=_process_dataset(glob.glob(p1+'*2007USAGI*')[0])\n",
    "ds89=_process_dataset(glob.glob(p1+'*2007PABUK*')[0])\n",
    "ds90=_process_dataset(glob.glob(p1+'*2007SEPAT*')[0])\n",
    "ds91=_process_dataset(glob.glob(p1+'*2007FITOW*')[0])\n",
    "ds92=_process_dataset(glob.glob(p1+'*2007DANAS*')[0])\n",
    "ds93=_process_dataset(glob.glob(p1+'*2007NARI*')[0])\n",
    "ds94=_process_dataset(glob.glob(p1+'*2007WIPHA*')[0])\n",
    "ds95=_process_dataset(glob.glob(p1+'*2007LEKIMA*')[0])\n",
    "ds96=_process_dataset(glob.glob(p1+'*2007KROSA*')[0])\n",
    "ds97=_process_dataset(glob.glob(p1+'*2007LINGLING*')[0])\n",
    "ds98=_process_dataset(glob.glob(p1+'*2007PEIPAH*')[0])\n",
    "ds99=_process_dataset(glob.glob(p1+'*2007HAGIBIS*')[0])\n",
    "ds100=_process_dataset(glob.glob(p1+'*2007MITAG*')[0])\n",
    "ds101=_process_dataset(glob.glob(p1+'*2006CHANCHU*')[0])\n",
    "ds102=_process_dataset(glob.glob(p1+'*2006EWINIAR*')[0])\n",
    "ds103=_process_dataset(glob.glob(p1+'*2006BILIS*')[0])\n",
    "ds104=_process_dataset(glob.glob(p1+'*2006KAEMI*')[0])\n",
    "ds105=_process_dataset(glob.glob(p1+'*2006PRAPIROON*')[0])\n",
    "ds106=_process_dataset(glob.glob(p1+'*2006SAOMAI*')[0])\n",
    "ds107=_process_dataset(glob.glob(p1+'*2006WUKONG*')[0])\n",
    "ds108=_process_dataset(glob.glob(p1+'*2006IOKE*')[0])\n",
    "ds109=_process_dataset(glob.glob(p1+'*2006SHANSHAN*')[0])\n",
    "ds110=_process_dataset(glob.glob(p1+'*2006MUKDA*')[0])\n",
    "ds111=_process_dataset(glob.glob(p1+'*2006XANGSANE*')[0])\n",
    "ds112=_process_dataset(glob.glob(p1+'*2006BEBINCA*')[0])\n",
    "ds113=_process_dataset(glob.glob(p1+'*2006SOULIK*')[0])\n",
    "ds114=_process_dataset(glob.glob(p1+'*2006CIMARON*')[0])\n",
    "ds115=_process_dataset(glob.glob(p1+'*2006CHEBI*')[0])\n",
    "ds116=_process_dataset(glob.glob(p1+'*2006DURIAN*')[0])\n",
    "ds117=_process_dataset(glob.glob(p1+'*2006UTOR*')[0])\n",
    "ds118=_process_dataset(glob.glob(p1+'*2005KULAP*')[0])\n",
    "ds119=_process_dataset(glob.glob(p1+'*2005ROKE*')[0])\n",
    "ds120=_process_dataset(glob.glob(p1+'*2005SONCA*')[0])\n",
    "ds121=_process_dataset(glob.glob(p1+'*2005HAITANG*')[0])\n",
    "ds122=_process_dataset(glob.glob(p1+'*2005NALGAE*')[0])\n",
    "ds123=_process_dataset(glob.glob(p1+'*2005BANYAN*')[0])\n",
    "ds124=_process_dataset(glob.glob(p1+'*2005MATSA*')[0])\n",
    "ds125=_process_dataset(glob.glob(p1+'*2005GUCHOL*')[0])\n",
    "ds126=_process_dataset(glob.glob(p1+'*2005MAWAR*')[0])\n",
    "ds127=_process_dataset(glob.glob(p1+'*2005TALIM*')[0])\n",
    "ds128=_process_dataset(glob.glob(p1+'*2005NABI*')[0])\n",
    "ds129=_process_dataset(glob.glob(p1+'*2005KHANUN*')[0])\n",
    "ds130=_process_dataset(glob.glob(p1+'*2005DAMREY*')[0])\n",
    "ds131=_process_dataset(glob.glob(p1+'*2005SAOLA*')[0])\n",
    "ds132=_process_dataset(glob.glob(p1+'*2005LONGWANG*')[0])\n",
    "ds133=_process_dataset(glob.glob(p1+'*2005KIROGI*')[0])\n",
    "ds134=_process_dataset(glob.glob(p1+'*2005TEMBIN*')[0])\n",
    "ds135=_process_dataset(glob.glob(p1+'*2005BOLAVEN*')[0])\n",
    "ds136=_process_dataset(glob.glob(p1+'*2004SUDAL*')[0])\n",
    "ds137=_process_dataset(glob.glob(p1+'*2004NIDA*')[0])\n",
    "ds138=_process_dataset(glob.glob(p1+'*2004CHANTHU*')[0])\n",
    "ds139=_process_dataset(glob.glob(p1+'*2004DIANMU*')[0])\n",
    "ds140=_process_dataset(glob.glob(p1+'*2004MINDULLE*')[0])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28acfd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds141=_process_dataset(glob.glob(p1+'*2004TINGTING*')[0])\n",
    "ds142=_process_dataset(glob.glob(p1+'*2004NAMTHEUN*')[0])\n",
    "ds143=_process_dataset(glob.glob(p1+'*2004MERANTI*')[0])\n",
    "ds144=_process_dataset(glob.glob(p1+'*2004RANANIM*')[0])\n",
    "ds145=_process_dataset(glob.glob(p1+'*2004MEGI*')[0])\n",
    "ds146=_process_dataset(glob.glob(p1+'*2004CHABA*')[0])\n",
    "ds147=_process_dataset(glob.glob(p1+'*2004AERE*')[0])\n",
    "ds148=_process_dataset(glob.glob(p1+'*2004SONGDA*')[0])\n",
    "ds149=_process_dataset(glob.glob(p1+'*2004MEARI*')[0])\n",
    "ds150=_process_dataset(glob.glob(p1+'*2004MA-ON*')[0])\n",
    "ds151=_process_dataset(glob.glob(p1+'*2004TOKAGE*')[0])\n",
    "ds152=_process_dataset(glob.glob(p1+'*2004NOCK-TEN*')[0])\n",
    "ds153=_process_dataset(glob.glob(p1+'*2004MUIFA*')[0])\n",
    "ds154=_process_dataset(glob.glob(p1+'*2004NANMADOL*')[0])\n",
    "ds155=_process_dataset(glob.glob(p1+'*2004NORU*')[0])\n",
    "ds156=_process_dataset(glob.glob(p1+'*2003SOUDELOR*')[0])\n",
    "ds157=_process_dataset(glob.glob(p1+'*2003KUJIRA*')[0])\n",
    "ds158=_process_dataset(glob.glob(p1+'*2003CHAN-HOM*')[0])\n",
    "ds159=_process_dataset(glob.glob(p1+'*2003IMBUDO*')[0])\n",
    "ds160=_process_dataset(glob.glob(p1+'*2003NANGKA*')[0])\n",
    "ds161=_process_dataset(glob.glob(p1+'*2003KONI*')[0])\n",
    "ds162=_process_dataset(glob.glob(p1+'*2003ETAU*')[0])\n",
    "ds163=_process_dataset(glob.glob(p1+'*2003KROVANH*')[0])\n",
    "ds164=_process_dataset(glob.glob(p1+'*2003DUJUAN*')[0])\n",
    "ds165=_process_dataset(glob.glob(p1+'*2003MAEMI*')[0])\n",
    "ds166=_process_dataset(glob.glob(p1+'*2003CHOI-WAN*')[0])\n",
    "ds167=_process_dataset(glob.glob(p1+'*2003KOPPU*')[0])\n",
    "ds168=_process_dataset(glob.glob(p1+'*2003KETSANA*')[0])\n",
    "ds169=_process_dataset(glob.glob(p1+'*2003MELOR*')[0])\n",
    "ds170=_process_dataset(glob.glob(p1+'*2003NEPARTAK*')[0])\n",
    "ds171=_process_dataset(glob.glob(p1+'*2003LUPIT*')[0])\n",
    "ds172=_process_dataset(glob.glob(p1+'*2002MITAG*')[0])\n",
    "ds173=_process_dataset(glob.glob(p1+'*2002HAGIBIS*')[0])\n",
    "ds174=_process_dataset(glob.glob(p1+'*2002CHATAAN*')[0])\n",
    "ds175=_process_dataset(glob.glob(p1+'*2002RAMMASUN*')[0])\n",
    "ds176=_process_dataset(glob.glob(p1+'*2002HALONG*')[0])\n",
    "ds177=_process_dataset(glob.glob(p1+'*2002FENGSHEN*')[0])\n",
    "ds178=_process_dataset(glob.glob(p1+'*2002FUNG-WONG*')[0])\n",
    "ds179=_process_dataset(glob.glob(p1+'*2002PHANFONE*')[0])\n",
    "ds180=_process_dataset(glob.glob(p1+'*2002RUSA*')[0])\n",
    "ds181=_process_dataset(glob.glob(p1+'*2002ELE*')[0])\n",
    "ds182=_process_dataset(glob.glob(p1+'*2002SINLAKU*')[0])\n",
    "ds183=_process_dataset(glob.glob(p1+'*2002HAGUPIT*')[0])\n",
    "ds184=_process_dataset(glob.glob(p1+'*2002MEKKHALA*')[0])\n",
    "ds185=_process_dataset(glob.glob(p1+'*2002HIGOS*')[0])\n",
    "ds186=_process_dataset(glob.glob(p1+'*2002BAVI*')[0])\n",
    "ds187=_process_dataset(glob.glob(p1+'*2002HUKO*')[0])\n",
    "ds188=_process_dataset(glob.glob(p1+'*2002HAISHEN*')[0])\n",
    "ds189=_process_dataset(glob.glob(p1+'*2002PONGSONA*')[0])\n",
    "ds190=_process_dataset(glob.glob(p1+'*2001CIMARON*')[0])\n",
    "ds191=_process_dataset(glob.glob(p1+'*2001CHEBI*')[0])\n",
    "ds192=_process_dataset(glob.glob(p1+'*2001UTOR*')[0])\n",
    "ds193=_process_dataset(glob.glob(p1+'*2001KONG-REY*')[0])\n",
    "ds194=_process_dataset(glob.glob(p1+'*2001FRANCISCO*')[0])\n",
    "ds195=_process_dataset(glob.glob(p1+'*2001MAN-YI*')[0])\n",
    "ds196=_process_dataset(glob.glob(p1+'*2001PABUK*')[0])\n",
    "ds197=_process_dataset(glob.glob(p1+'*2001WUTIP*')[0])\n",
    "ds198=_process_dataset(glob.glob(p1+'*2001FITOW*')[0])\n",
    "ds199=_process_dataset(glob.glob(p1+'*2001NARI*')[0])\n",
    "ds200=_process_dataset(glob.glob(p1+'*2001VIPA*')[0])\n",
    "ds201=_process_dataset(glob.glob(p1+'*2001FRANCISCO*')[0])\n",
    "ds202=_process_dataset(glob.glob(p1+'*2001LEKIMA*')[0])\n",
    "ds203=_process_dataset(glob.glob(p1+'*2001KROSA*')[0])\n",
    "ds204=_process_dataset(glob.glob(p1+'*2001HAIYAN*')[0])\n",
    "ds205=_process_dataset(glob.glob(p1+'*2001PODUL*')[0])\n",
    "ds206=_process_dataset(glob.glob(p1+'*2001LINGLING*')[0])\n",
    "ds207=_process_dataset(glob.glob(p1+'*2001FAXAI*')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0e7d96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tcwp1=ds1.values\n",
    "tcwp2=ds2.values\n",
    "tcwp3=ds3.values\n",
    "tcwp4=ds4.values\n",
    "tcwp5=ds5.values\n",
    "tcwp6=ds6.values\n",
    "tcwp7=ds7.values\n",
    "tcwp8=ds8.values\n",
    "tcwp9=ds9.values\n",
    "tcwp10=ds10.values\n",
    "tcwp11=ds11.values\n",
    "tcwp12=ds12.values\n",
    "tcwp13=ds13.values\n",
    "tcwp14=ds14.values\n",
    "tcwp15=ds15.values\n",
    "tcwp16=ds16.values\n",
    "tcwp17=ds17.values\n",
    "tcwp18=ds18.values\n",
    "tcwp19=ds19.values\n",
    "tcwp20=ds20.values\n",
    "tcwp21=ds21.values\n",
    "tcwp22=ds22.values\n",
    "tcwp23=ds23.values\n",
    "tcwp24=ds24.values\n",
    "tcwp25=ds25.values\n",
    "tcwp26=ds26.values\n",
    "tcwp27=ds27.values\n",
    "tcwp28=ds28.values\n",
    "tcwp29=ds29.values\n",
    "tcwp30=ds30.values\n",
    "tcwp31=ds31.values\n",
    "tcwp32=ds32.values\n",
    "tcwp33=ds33.values\n",
    "tcwp34=ds34.values\n",
    "tcwp35=ds35.values\n",
    "tcwp36=ds36.values\n",
    "tcwp37=ds37.values\n",
    "tcwp38=ds38.values\n",
    "tcwp39=ds39.values\n",
    "tcwp40=ds40.values\n",
    "tcwp41=ds41.values\n",
    "tcwp42=ds42.values\n",
    "tcwp43=ds43.values\n",
    "tcwp44=ds44.values\n",
    "tcwp45=ds45.values\n",
    "tcwp46=ds46.values\n",
    "tcwp47=ds47.values\n",
    "tcwp48=ds48.values\n",
    "tcwp49=ds49.values\n",
    "tcwp50=ds50.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70091e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tcwp51=ds51.values\n",
    "tcwp52=ds52.values\n",
    "tcwp53=ds53.values\n",
    "tcwp54=ds54.values\n",
    "tcwp55=ds55.values\n",
    "tcwp56=ds56.values\n",
    "tcwp57=ds57.values\n",
    "tcwp58=ds58.values\n",
    "tcwp59=ds59.values\n",
    "tcwp60=ds60.values\n",
    "tcwp61=ds61.values\n",
    "tcwp62=ds62.values\n",
    "tcwp63=ds63.values\n",
    "tcwp64=ds64.values\n",
    "tcwp65=ds65.values\n",
    "tcwp66=ds66.values\n",
    "tcwp67=ds67.values\n",
    "tcwp68=ds68.values\n",
    "tcwp69=ds69.values\n",
    "tcwp70=ds70.values\n",
    "tcwp71=ds71.values\n",
    "tcwp72=ds72.values\n",
    "tcwp73=ds73.values\n",
    "tcwp74=ds74.values\n",
    "tcwp75=ds75.values\n",
    "tcwp76=ds76.values\n",
    "tcwp77=ds77.values\n",
    "tcwp78=ds78.values\n",
    "tcwp79=ds79.values\n",
    "tcwp80=ds80.values\n",
    "tcwp81=ds81.values\n",
    "tcwp82=ds82.values\n",
    "tcwp83=ds83.values\n",
    "tcwp84=ds84.values\n",
    "tcwp85=ds85.values\n",
    "tcwp86=ds86.values\n",
    "tcwp87=ds87.values\n",
    "tcwp88=ds88.values\n",
    "tcwp89=ds89.values\n",
    "tcwp90=ds90.values\n",
    "tcwp91=ds91.values\n",
    "tcwp92=ds92.values\n",
    "tcwp93=ds93.values\n",
    "tcwp94=ds94.values\n",
    "tcwp95=ds95.values\n",
    "tcwp96=ds96.values\n",
    "tcwp97=ds97.values\n",
    "tcwp98=ds98.values\n",
    "tcwp99=ds99.values\n",
    "tcwp100=ds100.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "757cc443",
   "metadata": {},
   "outputs": [],
   "source": [
    "tcwp101=ds101.values\n",
    "tcwp102=ds102.values\n",
    "tcwp103=ds103.values\n",
    "tcwp104=ds104.values\n",
    "tcwp105=ds105.values\n",
    "tcwp106=ds106.values\n",
    "tcwp107=ds107.values\n",
    "tcwp108=ds108.values\n",
    "tcwp109=ds109.values\n",
    "tcwp110=ds110.values\n",
    "tcwp111=ds111.values\n",
    "tcwp112=ds112.values\n",
    "tcwp113=ds113.values\n",
    "tcwp114=ds114.values\n",
    "tcwp115=ds115.values\n",
    "tcwp116=ds116.values\n",
    "tcwp117=ds117.values\n",
    "tcwp118=ds118.values\n",
    "tcwp119=ds119.values\n",
    "tcwp120=ds120.values\n",
    "tcwp121=ds121.values\n",
    "tcwp122=ds122.values\n",
    "tcwp123=ds123.values\n",
    "tcwp124=ds124.values\n",
    "tcwp125=ds125.values\n",
    "tcwp126=ds126.values\n",
    "tcwp127=ds127.values\n",
    "tcwp128=ds128.values\n",
    "tcwp129=ds129.values\n",
    "tcwp130=ds130.values\n",
    "tcwp131=ds131.values\n",
    "tcwp132=ds132.values\n",
    "tcwp133=ds133.values\n",
    "tcwp134=ds134.values\n",
    "tcwp135=ds135.values\n",
    "tcwp136=ds136.values\n",
    "tcwp137=ds137.values\n",
    "tcwp138=ds138.values\n",
    "tcwp139=ds139.values\n",
    "tcwp140=ds140.values\n",
    "tcwp141=ds141.values\n",
    "tcwp142=ds142.values\n",
    "tcwp143=ds143.values\n",
    "tcwp144=ds144.values\n",
    "tcwp145=ds145.values\n",
    "tcwp146=ds146.values\n",
    "tcwp147=ds147.values\n",
    "tcwp148=ds148.values\n",
    "tcwp149=ds149.values\n",
    "tcwp150=ds150.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61be25ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "tcwp151=ds151.values\n",
    "tcwp152=ds152.values\n",
    "tcwp153=ds153.values\n",
    "tcwp154=ds154.values\n",
    "tcwp155=ds155.values\n",
    "tcwp156=ds156.values\n",
    "tcwp157=ds157.values\n",
    "tcwp158=ds158.values\n",
    "tcwp159=ds159.values\n",
    "tcwp160=ds160.values\n",
    "tcwp161=ds161.values\n",
    "tcwp162=ds162.values\n",
    "tcwp163=ds163.values\n",
    "tcwp164=ds164.values\n",
    "tcwp165=ds165.values\n",
    "tcwp166=ds166.values\n",
    "tcwp167=ds167.values\n",
    "tcwp168=ds168.values\n",
    "tcwp169=ds169.values\n",
    "tcwp170=ds170.values\n",
    "tcwp171=ds171.values\n",
    "tcwp172=ds172.values\n",
    "tcwp173=ds173.values\n",
    "tcwp174=ds174.values\n",
    "tcwp175=ds175.values\n",
    "tcwp176=ds176.values\n",
    "tcwp177=ds177.values\n",
    "tcwp178=ds178.values\n",
    "tcwp179=ds179.values\n",
    "tcwp180=ds180.values\n",
    "tcwp181=ds181.values\n",
    "tcwp182=ds182.values\n",
    "tcwp183=ds183.values\n",
    "tcwp184=ds184.values\n",
    "tcwp185=ds185.values\n",
    "tcwp186=ds186.values\n",
    "tcwp187=ds187.values\n",
    "tcwp188=ds188.values\n",
    "tcwp189=ds189.values\n",
    "tcwp190=ds190.values\n",
    "tcwp191=ds191.values\n",
    "tcwp192=ds192.values\n",
    "tcwp193=ds193.values\n",
    "tcwp194=ds194.values\n",
    "tcwp195=ds195.values\n",
    "tcwp196=ds196.values\n",
    "tcwp197=ds197.values\n",
    "tcwp198=ds198.values\n",
    "tcwp199=ds199.values\n",
    "tcwp200=ds200.values\n",
    "tcwp201=ds201.values\n",
    "tcwp202=ds202.values\n",
    "tcwp203=ds203.values\n",
    "tcwp204=ds204.values\n",
    "tcwp205=ds205.values\n",
    "tcwp206=ds206.values\n",
    "tcwp207=ds207.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a35a809",
   "metadata": {},
   "source": [
    "West Pacific Storms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "788b83f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddwp={'cyclone2':tcwp2,'cyclone3':tcwp3,'cyclone4':tcwp4,'cyclone5':tcwp5,'cyclone6':tcwp6,\n",
    "      'cyclone7':tcwp7, 'cyclone8':tcwp8,'cyclone9':tcwp9,'cyclone10':tcwp10,'cyclone11':tcwp11,'cyclone12':tcwp12,\n",
    "      'cyclone13':tcwp13,'cyclone14':tcwp14,'cyclone15':tcwp15,'cyclone16':tcwp16,'cyclone17':tcwp17,\n",
    "      'cyclone18':tcwp18,'cyclone19':tcwp19,'cyclone21':tcwp21,'cyclone22':tcwp22,'cyclone23':tcwp23,'cyclone24':tcwp24,\n",
    "      'cyclone25':tcwp25,'cyclone26':tcwp26,'cyclone27':tcwp27,'cyclone28':tcwp28,'cyclone29':tcwp29,'cyclone30':tcwp30,\n",
    "      'cyclone31':tcwp31,'cyclone32':tcwp32,'cyclone33':tcwp33,'cyclone34':tcwp34,'cyclone35':tcwp35,'cyclone36':tcwp36,\n",
    "      'cyclone37':tcwp37,'cyclone38':tcwp38,'cyclone39':tcwp39,'cyclone40':tcwp40,'cyclone41':tcwp41,'cyclone42':tcwp42,\n",
    "      'cyclone43':tcwp43,'cyclone44':tcwp44,'cyclone45':tcwp45,'cyclone46':tcwp46,'cyclone47':tcwp47,'cyclone48':tcwp48,\n",
    "      'cyclone49':tcwp49,'cyclone50':tcwp50,'cyclone51':tcwp51,\n",
    "      'cyclone52':tcwp52, 'cyclone53':tcwp53,'cyclone54':tcwp54,'cyclone55':tcwp55,'cyclone56':tcwp56,'cyclone57':tcwp57,\n",
    "      'cyclone58':tcwp58,'cyclone59':tcwp59,'cyclone60':tcwp60,'cyclone61':tcwp61,'cyclone62':tcwp62,'cyclone63':tcwp63,\n",
    "      'cyclone64':tcwp64,'cyclone65':tcwp65,'cyclone66':tcwp66,'cyclone67':tcwp67,'cyclone68':tcwp68,'cyclone69':tcwp69,\n",
    "      'cyclone70':tcwp70,'cyclone71':tcwp71,'cyclone72':tcwp72,'cyclone73':tcwp73,'cyclone74':tcwp74,'cyclone75':tcwp75,\n",
    "      'cyclone76':tcwp76,'cyclone77':tcwp77,'cyclone78':tcwp78,'cyclone79':tcwp79,'cyclone80':tcwp80,'cyclone81':tcwp81,\n",
    "      'cyclone82':tcwp82,'cyclone83':tcwp83,'cyclone84':tcwp84,'cyclone85':tcwp85,'cyclone86':tcwp86,'cyclone87':tcwp87,\n",
    "      'cyclone88':tcwp88,'cyclone89':tcwp89,'cyclone90':tcwp90,'cyclone91':tcwp91,'cyclone92':tcwp92,'cyclone93':tcwp93,\n",
    "      'cyclone94':tcwp94,'cyclone95':tcwp95,'cyclone96':tcwp96,'cyclone97':tcwp97,'cyclone98':tcwp98,\n",
    "      'cyclone99':tcwp99,'cyclone100':tcwp100,'cyclone101':tcwp101,'cyclone102':tcwp102,'cyclone103':tcwp103,'cyclone104':tcwp104,\n",
    "      'cyclone105':tcwp105,'cyclone106':tcwp106,'cyclone107':tcwp107,'cyclone108':tcwp108,'cyclone109':tcwp109,\n",
    "      'cyclone110':tcwp110,'cyclone111':tcwp111,'cyclone112':tcwp112,'cyclone113':tcwp113,'cyclone114':tcwp114,\n",
    "      'cyclone115':tcwp115,'cyclone116':tcwp116,'cyclone117':tcwp117,'cyclone118':tcwp118,'cyclone119':tcwp119,\n",
    "      'cyclone120':tcwp120,'cyclone121':tcwp121,'cyclone122':tcwp122,'cyclone123':tcwp123,'cyclone124':tcwp124,\n",
    "      'cyclone125':tcwp125,'cyclone126':tcwp126,'cyclone127':tcwp127,'cyclone128':tcwp128,'cyclone129':tcwp129,\n",
    "      'cyclone130':tcwp130,'cyclone131':tcwp131,'cyclone132':tcwp132,'cyclone133':tcwp133,'cyclone134':tcwp134,\n",
    "      'cyclone135':tcwp135,'cyclone136':tcwp136,'cyclone137':tcwp137,'cyclone138':tcwp138,'cyclone139':tcwp139,\n",
    "      'cyclone140':tcwp140,'cyclone141':tcwp141,'cyclone142':tcwp142,'cyclone143':tcwp143,'cyclone144':tcwp144,\n",
    "      'cyclone145':tcwp145,'cyclone146':tcwp146,'cyclone147':tcwp147,'cyclone148':tcwp148,'cyclone149':tcwp149,'cyclone150':tcwp150,\n",
    "      'cyclone151':tcwp151,'cyclone152':tcwp152,'cyclone153':tcwp153,'cyclone154':tcwp154,'cyclone155':tcwp155,\n",
    "      'cyclone156':tcwp156,'cyclone157':tcwp157,'cyclone158':tcwp158,'cyclone159':tcwp159,'cyclone160':tcwp160,\n",
    "      'cyclone161':tcwp161,'cyclone162':tcwp162,'cyclone163':tcwp163,'cyclone164':tcwp164,'cyclone165':tcwp165,\n",
    "      'cyclone166':tcwp166,'cyclone167':tcwp167,'cyclone168':tcwp168,'cyclone169':tcwp169,'cyclone170':tcwp170,\n",
    "      'cyclone171':tcwp171,'cyclone172':tcwp172,'cyclone173':tcwp173,'cyclone174':tcwp174,'cyclone175':tcwp175,\n",
    "      'cyclone176':tcwp176,'cyclone177':tcwp177,'cyclone178':tcwp178,'cyclone179':tcwp179,'cyclone180':tcwp180,\n",
    "      'cyclone181':tcwp181,'cyclone182':tcwp182,'cyclone183':tcwp183,'cyclone184':tcwp184,'cyclone185':tcwp185,\n",
    "      'cyclone186':tcwp186,'cyclone187':tcwp187,'cyclone188':tcwp188,'cyclone189':tcwp189,'cyclone190':tcwp190,\n",
    "      'cyclone191':tcwp191,'cyclone192':tcwp192,'cyclone193':tcwp193,'cyclone194':tcwp194,'cyclone195':tcwp195,\n",
    "      'cyclone196':tcwp196,'cylone197':tcwp197,'cyclone198':tcwp198,'cyclone199':tcwp199,'cyclone200':tcwp200,\n",
    "      'cyclone201':tcwp201,'cyclone202':tcwp202,'cyclone203':tcwp203,'cyclone204':tcwp204,'cyclone205':tcwp205,\n",
    "      'cyclone206':tcwp206,'cyclone207':tcwp207}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9e661b8-ba77-4c55-ab27-a7050294d1c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5be42a6efc0241d9b75e82bba665155d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from natsort import natsorted\n",
    "testcyclone_dict = {}\n",
    "newtestfilelist_f = natsorted(glob.glob('/work/FAC/FGSE/IDYST/tbeucler/default/saranya/causal/timeseries_csv/new_storms_wpac/*'))[-55-7:-7]\n",
    "for ind,obj in tqdm(enumerate(newtestfilelist_f)):\n",
    "    testcyclone_dict['testcyclone'+str(ind)] = _process_dataset(obj).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "67b16616",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pipeline:\n",
    "    \"\"\"\n",
    "    Tigramite and Linear Regression Pipeline\n",
    "    \"\"\"\n",
    "    def __init__(self,data,pc_alpha,alpha_level,pc_type='run_pcstable' or 'pcmci',tau_min0=None,tau_max0=None,\n",
    "                 target='precip',var_name=None,seed=None,cond_ind_test=ParCorr()):\n",
    "        self.pc_alpha = pc_alpha\n",
    "        self.alpha_level = alpha_level\n",
    "        self.data = data\n",
    "        self.pc_type = pc_type\n",
    "        self.target = target\n",
    "        self.tau_min0 = tau_min0\n",
    "        self.tau_max0 = tau_max0\n",
    "        self.var_name = var_name\n",
    "        self.seed = seed\n",
    "        self.cond_ind_test = cond_ind_test\n",
    "        \n",
    "    #################################################################################\n",
    "    # Step 0: Split\n",
    "    #################################################################################\n",
    "    def splitdata(self,testindex=None):\n",
    "        datae = self.data.copy()\n",
    "        traindata = {}\n",
    "        testdata = {}\n",
    "        validdata = {}\n",
    "        validindex,newtestindex = testindex[:int(len(testindex)/2)],testindex[int(len(testindex)/2):]\n",
    "        for obj in datae.keys():\n",
    "            number = int(obj[7:])\n",
    "            if number in list(newtestindex):\n",
    "                testdata['cyclone'+str(number)] = datae['cyclone'+str(number)]\n",
    "            elif number in list(validindex):\n",
    "                validdata['cyclone'+str(number)] = datae['cyclone'+str(number)]\n",
    "            else:\n",
    "                traindata['cyclone'+str(number)] = datae['cyclone'+str(number)]\n",
    "        return traindata,validdata,testdata\n",
    "    \n",
    "    #################################################################################\n",
    "    # Step 1: Tigramite\n",
    "    #################################################################################\n",
    "    def run_tigramite(self,lengthtrain=None):\n",
    "        #assert len(self.data)==lengthtrain,\"Wrong shape!\"\n",
    "        datae = self.data.copy()\n",
    "        dataframe =  pp.DataFrame(datae,analysis_mode ='multiple', var_names=var_names)\n",
    "        #################################################################################\n",
    "        # Sel links\n",
    "        #################################################################################\n",
    "        for member in dataframe.values.keys():\n",
    "            children = [0,1,2]\n",
    "            parents = np.arange(0,234)\n",
    "            sel_links = select_links(self.tau_min0, self.tau_max0, parents, children)\n",
    "        #################################################################################\n",
    "        # Run Tigramite\n",
    "        #################################################################################        \n",
    "        pcmci = PCMCI(dataframe = dataframe, cond_ind_test = self.cond_ind_test)\n",
    "        if self.pc_type=='run_pcstable':\n",
    "            results = pcmci.run_pc_stable(selected_links=sel_links, tau_min=self.tau_min0, tau_max=self.tau_max0,\\\n",
    "                                          pc_alpha=self.pc_alpha)\n",
    "        elif self.pc_type=='pcmci':\n",
    "            results = pcmci.run_pcmci(selected_links=sel_links, tau_min=self.tau_min0, tau_max=self.tau_max0,\\\n",
    "                                      pc_alpha=self.pc_alpha)\n",
    "        elif self.pc_type=='lagcorr':\n",
    "            results = pcmci.get_lagged_dependencies(selected_links=sel_links, tau_min=self.tau_min0, \n",
    "                                                    tau_max=self.tau_max0, \n",
    "                                                    val_only=False)['val_matrix']\n",
    "\n",
    "        pcmci.verbosity = 2\n",
    "        #################################################################################\n",
    "        # Test\n",
    "        #################################################################################   \n",
    "        #pcmci.print_results(results,self.alpha_level)\n",
    "        #pcmci.print_significant_links(p_matrix=results['p_matrix'],\n",
    "        #val_matrix = results['val_matrix'],\n",
    "        #alpha_level = self.alpha_level)\n",
    "        return results\n",
    "    \n",
    "    #################################################################################\n",
    "    # Step 2: Linear Regression\n",
    "    #################################################################################\n",
    "    # Helper functions\n",
    "    #################################################################################\n",
    "    def random_testindex(self,totalexp=None,testexp=None):\n",
    "        from numpy.random import default_rng\n",
    "        rng = default_rng(self.seed)\n",
    "        seed = rng.choice(totalexp, testexp, replace=False)\n",
    "        return seed\n",
    "    \n",
    "    def extract_lag_info(self,datar=None,varindex=None,lag=None):\n",
    "        temp = datar[:,varindex] # Full time series\n",
    "        store = []\n",
    "        for timeindex in range(len(temp)):\n",
    "            if timeindex < np.abs(lag):\n",
    "                store.append(np.nan)\n",
    "            elif timeindex > len(temp)-1-np.abs(lag):\n",
    "                store.append(np.nan)\n",
    "            else:\n",
    "                store.append(temp[timeindex-np.abs(lag)])\n",
    "        return store\n",
    "    \n",
    "    def extract_var_and_lag(self,pcmci_results=None,p_or_q='p' or 'q'):\n",
    "        datae = self.data.copy()\n",
    "        dataframe =  pp.DataFrame(datae,analysis_mode ='multiple', var_names=var_names,missing_flag=-999.)\n",
    "        pcmci = PCMCI(dataframe = dataframe, cond_ind_test = self.cond_ind_test)\n",
    "        #################################################################################\n",
    "        # Sel links\n",
    "        #################################################################################\n",
    "        for member in dataframe.values.keys():\n",
    "            children = [0,1,2]\n",
    "            parents = np.arange(0,234)\n",
    "            #parents = np.arange(0,self.parent)\n",
    "            sel_links = select_links(self.tau_min0, self.tau_max0, parents, children)\n",
    "        \n",
    "        q_matrix = pcmci.get_corrected_pvalues(p_matrix=pcmci_results['p_matrix'],\n",
    "                                               selected_links = sel_links, \n",
    "                                               tau_min=self.tau_min0,tau_max=self.tau_max0, fdr_method='fdr_bh')\n",
    "        #################################################################################\n",
    "        # Save vars and lags\n",
    "        ##################turin###############################################################\n",
    "        if p_or_q=='p':\n",
    "            sig_links = (pcmci_results['p_matrix'].copy() <= self.alpha_level)\n",
    "        elif p_or_q=='q':\n",
    "            sig_links = (q_matrix.copy() <= self.alpha_level)\n",
    "        arr = []\n",
    "        for j in range(3):\n",
    "            links = {(p[0], -p[1]): np.abs(pcmci_results['val_matrix'][p[0],j,abs(p[1])]) for p in zip(*np.where(sig_links[:,j,:]))}\n",
    "            # Sort by value\n",
    "            sorted_links = sorted(links, key=links.get, reverse=True)\n",
    "            arr.append(sorted_links)\n",
    "        return arrturin\n",
    "    \n",
    "    #################################################################################\n",
    "    # Process functions\n",
    "    #################################################################################\n",
    "    def preproc_ts_withnan(self,links=None,group=None,trainmean=None,trainstd=None):\n",
    "        if self.target=='precip':\n",
    "            arrtarget,ytarget = links[0],[self.data[obj][:,0] for obj in self.data.keys()]\n",
    "        elif self.target=='pmin':\n",
    "            arrtarget,ytarget = links[1],[self.data[obj][:,1] for obj in self.data.keys()]\n",
    "        elif self.target=='v10':\n",
    "            arrtarget,ytarget = links[2],[self.data[obj][:,2] for obj in self.data.keys()]\n",
    "        \n",
    "        # 1. Extract time series with nan\n",
    "        varindexstore,lagstore,TS_store,flatTS_store = [],[],[],[]\n",
    "        for varindex,lag in arrtarget:\n",
    "            varindexstore.append(varindex)\n",
    "            lagstore.append(lag)\n",
    "            tempp = [self.extract_lag_info(datar=self.data[obj],varindex=varindex,lag=lag) for obj in self.data.keys()]\n",
    "            TS_store.append(tempp)\n",
    "            flatTS_store.append(np.concatenate([obj for obj in tempp]))\n",
    "        \n",
    "        # 2. Normalize\n",
    "        if group=='train':\n",
    "            TSnorml_store,meanstore,stdstore = [],[],[]\n",
    "            for i in range(len(TS_store)): #combination\n",
    "                tempmean,tempstd = np.nanmean(flatTS_store[i]),np.nanstd(flatTS_store[i])\n",
    "                TSnorml_store.append([(obj-tempmean)/tempstd for obj in TS_store[i]])\n",
    "                meanstore.append(tempmean)\n",
    "                stdstore.append(tempstd)\n",
    "        elif (group=='test') or (group=='valid'):\n",
    "            TSnorml_store = []\n",
    "            for i in range(len(TS_store)):\n",
    "                tempmean,tempstd = (trainmean[i]),(trainstd[i])\n",
    "                TSnorml_store.append([(obj-tempmean)/tempstd for obj in TS_store[i]])\n",
    "            \n",
    "        # 3. Concatenate\n",
    "        #validindex,testindex = validtestindex[0:int(np.round(len(validtestindex)/2))],\\\n",
    "        #validtestindex[int(np.round(len(validtestindex)/2)):]\n",
    "        \n",
    "        Xtrain_withnan_store = []\n",
    "        for i in range(len(TS_store)):\n",
    "            storelist = [i for j, i in enumerate(TSnorml_store[i])]\n",
    "            Xtrain_withnan_store.append(np.concatenate([obj for obj in storelist]))\n",
    "            \n",
    "        Ytrain = np.concatenate([i for j, i in enumerate(ytarget)])\n",
    "        if group=='train':\n",
    "            return Xtrain_withnan_store,Ytrain,meanstore,stdstore\n",
    "        elif group=='valid':\n",
    "            return Xtrain_withnan_store,Ytrain\n",
    "        elif group=='test':\n",
    "            return Xtrain_withnan_store,Ytrain\n",
    "    \n",
    "    def remove_nan(self,Xdict=None,ydict=None):\n",
    "        def _remove_nan(X=None,y=None):\n",
    "            X_nonan,Y_nonan = [],[]\n",
    "            X_withnan_storer = np.asarray(X).transpose()\n",
    "            for i in (range(len(y))):\n",
    "                tempX = X_withnan_storer[i,:]\n",
    "                if np.isnan(tempX).any():\n",
    "                    continue\n",
    "                else:\n",
    "                    X_nonan.append(tempX)\n",
    "                    Y_nonan.append(y[i])\n",
    "            return X_nonan,Y_nonan\n",
    "        Xtrain,ytrain = _remove_nan(X=Xdict['train'],y=ydict['train'])\n",
    "        Xvalid,yvalid = _remove_nan(X=Xdict['valid'],y=ydict['valid'])\n",
    "        Xtest,ytest = _remove_nan(X=Xdict['test'],y=ydict['test'])\n",
    "        Xnewtest,ynewtest = _remove_nan(X=Xdict['newtest'],y=ydict['newtest'])\n",
    "        return {'train':Xtrain,'valid':Xvalid,'test':Xtest,'newtest':Xnewtest},{'train':ytrain,'valid':yvalid,'test':ytest,'newtest':ynewtest}\n",
    "\n",
    "    def remove_999(self,Xdict=None,ydict=None):\n",
    "        def _remove_999(X=None,y=None):\n",
    "            X_nonan,Y_nonan = [],[]\n",
    "            X_withnan_storer = np.asarray(X).transpose()\n",
    "            for i in (range(len(y))):\n",
    "                tempX = X_withnan_storer[i,:]\n",
    "                if y[i]==-999.:\n",
    "                    continue\n",
    "                else:\n",
    "                    X_nonan.append(tempX)\n",
    "                    Y_nonan.append(y[i])\n",
    "            return X_nonan,Y_nonan\n",
    "        Xtrain,ytrain = _remove_999(X=Xdict['train'],y=ydict['train'])\n",
    "        Xvalid,yvalid = _remove_999(X=Xdict['valid'],y=ydict['valid'])\n",
    "        Xtest,ytest = _remove_999(X=Xdict['test'],y=ydict['test'])\n",
    "        Xnewtest,ynewtest = _remove_999(X=Xdict['newtest'],y=ydict['newtest'])\n",
    "        return {'train':Xtrain,'valid':Xvalid,'test':Xtest,'newtest':Xnewtest},{'train':ytrain,'valid':yvalid,'test':ytest,'newtest':ynewtest}\n",
    "    #################################################################################\n",
    "    # Train model\n",
    "    #################################################################################\n",
    "    def train_mlr(self,X=None,y=None):\n",
    "        regr = LinearRegression()\n",
    "        regr.fit(X['train'],y['train'])\n",
    "        return regr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e0a8252",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainMLR_target(traindata=None,validdata=None,testdata=None,newtestdata=None,target='precip' or 'pmin' or 'v10',seed=12345,tau_min=None,tau_max=None,pc_alpha=None):\n",
    "    ################################################################################################################\n",
    "    # 1. X,y with nan\n",
    "    Xtrain_nan,ytrain_nan,trainmean,trainstd = Pipeline(traindata,pc_alpha,alpha_level,pc_type='pcmci',\\\n",
    "                                                        tau_min0=tau_min,tau_max0=tau_max,\\\n",
    "                                                        target=target,var_name=var_names,\\\n",
    "                                                        seed=seed).preproc_ts_withnan(links=var_and_lag,group='train',\\\n",
    "                                                                                       trainmean=None,trainstd=None)\n",
    "    Xvalid_nan,yvalid_nan = Pipeline(validdata,pc_alpha,alpha_level,pc_type='pcmci',\\\n",
    "                                   tau_min0=tau_min,tau_max0=tau_max,target=target,\\\n",
    "                                   var_name=var_names,seed=seed).preproc_ts_withnan(links=var_and_lag,\\\n",
    "                                                                                     group='valid',\\\n",
    "                                                                                     trainmean=trainmean,\\\n",
    "                                                                                     trainstd=trainstd)\n",
    "    \n",
    "    Xtest_nan,ytest_nan = Pipeline(testdata,pc_alpha,alpha_level,pc_type='pcmci',\\\n",
    "                                   tau_min0=tau_min,tau_max0=tau_max,target=target,\\\n",
    "                                   var_name=var_names,seed=seed).preproc_ts_withnan(links=var_and_lag,\\\n",
    "                                                                                     group='test',\\\n",
    "                                                                                     trainmean=trainmean,\\\n",
    "                                                                                     trainstd=trainstd)\n",
    "    \n",
    "    Xnewtest_nan,ynewtest_nan = Pipeline(newtestdata,pc_alpha,alpha_level,pc_type='pcmci',\\\n",
    "                                   tau_min0=tau_min,tau_max0=tau_max,target=target,\\\n",
    "                                   var_name=var_names,seed=seed).preproc_ts_withnan(links=var_and_lag,\\\n",
    "                                                                                     group='test',\\\n",
    "                                                                                     trainmean=trainmean,\\\n",
    "                                                                                     trainstd=trainstd)\n",
    "    X_nan = {'train':Xtrain_nan,'valid':Xvalid_nan,'test':Xtest_nan,'newtest':Xnewtest_nan}\n",
    "    y_nan = {'train':ytrain_nan,'valid':yvalid_nan,'test':ytest_nan,'newtest':ynewtest_nan}\n",
    "    ################################################################################################################\n",
    "    # 2. remove nan\n",
    "    X_nonan,y_nonan = Pipeline(traindata,pc_alpha,alpha_level,pc_type='pcmci',\\\n",
    "                               tau_min0=tau_min,tau_max0=tau_max,target=target,\\\n",
    "                               var_name=var_names,seed=seed).remove_nan(Xdict=X_nan,ydict=y_nan)\n",
    "    ################################################################################################################\n",
    "    # 3. Train MLR\n",
    "    wpac_mlr = Pipeline(traindata,pc_alpha,alpha_level,pc_type='pcmci',\\\n",
    "                        tau_min0=tau_min,tau_max0=tau_max,target=target,\\\n",
    "                        var_name=var_names,seed=seed).train_mlr(X=X_nonan,y=y_nonan)\n",
    "    ################################################################################################################\n",
    "    return wpac_mlr,X_nonan,y_nonan\n",
    "    #return X_nan, y_nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9a92d8",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### PCSTABLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c852596c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def depickle(loc=None):\n",
    "    output = []\n",
    "    with open(loc,'rb') as f:\n",
    "        output.append(pickle.load(f))\n",
    "    return output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "510b00f9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.01,\n",
       " 0.04,\n",
       " 0.07,\n",
       " 0.1,\n",
       " 0.13,\n",
       " 0.16,\n",
       " 0.19,\n",
       " 0.22,\n",
       " 0.26,\n",
       " 0.29,\n",
       " 0.32,\n",
       " 0.35,\n",
       " 0.38,\n",
       " 0.41,\n",
       " 0.44,\n",
       " 0.47,\n",
       " 0.5,\n",
       " 0.53,\n",
       " 0.56,\n",
       " 0.59,\n",
       " 0.62,\n",
       " 0.65,\n",
       " 0.69,\n",
       " 0.72,\n",
       " 0.75,\n",
       " 0.78,\n",
       " 0.81,\n",
       " 0.84,\n",
       " 0.87,\n",
       " 0.9]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[np.round(obj,decimals=2) for obj in np.linspace(0.01,0.9,30)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1f04c834-e1a5-40ef-a0d1-39d3922ffd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def depickle(loc=None):\n",
    "    output = []\n",
    "    with open(loc,'rb') as f:\n",
    "        output.append(pickle.load(f))\n",
    "    return output[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b100469c-eb02-4cdf-9217-5c6cbbf5232e",
   "metadata": {},
   "source": [
    "#### Random Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0608692b-a869-4142-a76f-f5d62d3de943",
   "metadata": {},
   "outputs": [],
   "source": [
    "randomvarss, randomlagss = np.random.randint(low = 0, high = 234, size = 20),np.random.randint(low = -16, high = -2, size = 15)\n",
    "var_and_lagsRAN = [(aa,bb) for aa,bb in zip(randomvarss,randomlagss)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0d5d346c-87c7-4f4a-be76-5e409f7fc2ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(112, -13),\n",
       " (206, -7),\n",
       " (170, -4),\n",
       " (2, -4),\n",
       " (196, -11),\n",
       " (117, -6),\n",
       " (174, -9),\n",
       " (175, -5),\n",
       " (144, -5),\n",
       " (207, -10),\n",
       " (118, -5),\n",
       " (31, -9),\n",
       " (196, -4),\n",
       " (199, -11),\n",
       " (61, -16)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_and_lagsRAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f99d4900",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "def save_to_pickle(loc=None,var=None):\n",
    "    with open(loc,\"wb\") as f:\n",
    "        pickle.dump(var,f)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "057015d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15c9599a5d384c878b4e0eddb2ef0854",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "pc_alpha,alpha_level,splitsize,seednum=0.1,0.01,55,12348\n",
    "pc_type = 'run_pcstable'\n",
    "var_names=ds1.columns.values.tolist()\n",
    "\n",
    "for numlinks in tqdm(np.linspace(10,1000,100)):#,0.1,0.05,0.01,1e-3,1e-4,1e-5,1e-6,1e-7,1e-8]):\n",
    "    randomvarss, randomlagss = np.random.randint(low = 0, high = 234, size = int(numlinks)),np.random.randint(low = -24, high = -8, size = int(numlinks))\n",
    "    var_and_lagsRAN = [(aa,bb) for aa,bb in zip(randomvarss,randomlagss)]\n",
    "    testindex = (Pipeline(ddwp,pc_alpha,alpha_level,pc_type=pc_type,tau_min0=8,tau_max0=24,\\\n",
    "                          target=None,var_name=var_names,seed=seednum).random_testindex(205,splitsize))\n",
    "    traindata,validdata,testdata = Pipeline(ddwp,pc_alpha,alpha_level,pc_type=pc_type,tau_min0=8,tau_max0=24,\\\n",
    "                                            target='precip',var_name=var_names,seed=seednum).splitdata(testindex)\n",
    "    newtestdata = deepcopy(testcyclone_dict)\n",
    "    var_and_lag = [var_and_lagsRAN,var_and_lagsRAN,var_and_lagsRAN]\n",
    "    wpac_mlr_precip,X_precip,y_precip = trainMLR_target(traindata,validdata,testdata,newtestdata,'precip',seednum,8,24)\n",
    "    wpac_mlr_pmin,X_pmin,y_pmin = trainMLR_target(traindata,validdata,testdata,newtestdata,'pmin',seednum,8,24)\n",
    "    wpac_mlr_v10,X_v10,y_v10 = trainMLR_target(traindata,validdata,testdata,newtestdata,'v10',seednum,8,24)\n",
    "    save_to_pickle(loc='./store/random/'+str(seednum)+'/randomwpallnewtest_8_24_precip.obj.'+\\\n",
    "                   str(numlinks),\\\n",
    "                   var={'mlr':wpac_mlr_precip,'X':X_precip,'y':y_precip})\n",
    "    save_to_pickle(loc='./store/random/'+str(seednum)+'/randomwpallnewtest_8_24_pmin.obj.'+\\\n",
    "                   str(numlinks),\\\n",
    "                   var={'mlr':wpac_mlr_pmin,'X':X_pmin,'y':y_pmin})\n",
    "    save_to_pickle(loc='./store/random/'+str(seednum)+'/randomwpallnewtest_8_24_v10.obj.'+\\\n",
    "                   str(numlinks),\\\n",
    "                   var={'mlr':wpac_mlr_v10,'X':X_v10,'y':y_v10})\n",
    "    save_to_pickle(loc='./store/random/'+str(seednum)+'/randomwpallnewtest_8_24_lag_and_links.'+\\\n",
    "                   str(numlinks),var=var_and_lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a9c2bf52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescue_code(function):\n",
    "    import inspect\n",
    "    get_ipython().set_next_input(\"\".join(inspect.getsourcelines(function)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b8248c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rescue_code(save_to_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632bb432",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d01c2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6b8605",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
