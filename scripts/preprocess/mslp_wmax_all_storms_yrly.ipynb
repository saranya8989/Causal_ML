{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95b4e56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import netCDF4 as nf\n",
    "from netCDF4 import Dataset\n",
    "%matplotlib inline\n",
    "import glob\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bf47798",
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath=\"/work/FAC/FGSE/IDYST/tbeucler/default/saranya/Data/ECMWF/ERA5_25kmx3hr/\"\n",
    "path=\"/work/FAC/FGSE/IDYST/tbeucler/default/saranya/causal/besttracks/wp/\"\n",
    "output=\"/work/FAC/FGSE/IDYST/tbeucler/default/saranya/causal/create_ts/outputs/\"\n",
    "target=\"/work/FAC/FGSE/IDYST/tbeucler/default/saranya/causal/create_ts/outputs/targets/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "b4912ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "track = sorted(glob.glob(path+'wp_2016.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "c42e687a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracksDF = pd.read_csv(track[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "3aeea781",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NEPARTAK', 'OMAIS', 'CONSON', 'CHANTHU', 'MINDULLE', 'LIONROCK',\n",
       "       'MERANTI', 'MALAKAS', 'MEGI', 'SONGDA', 'AERE', 'MEARI',\n",
       "       'NOCK-TEN'], dtype=object)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracksDF['name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "53301721",
   "metadata": {},
   "outputs": [],
   "source": [
    "stormnames = list(tracksDF['name'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "4411343b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2016-07-02',\n",
       " '2016-07-02',\n",
       " '2016-07-02',\n",
       " '2016-07-02',\n",
       " '2016-07-03',\n",
       " '2016-07-03',\n",
       " '2016-07-03',\n",
       " '2016-07-03',\n",
       " '2016-07-03',\n",
       " '2016-07-03',\n",
       " '2016-07-03',\n",
       " '2016-07-03',\n",
       " '2016-07-04',\n",
       " '2016-07-04',\n",
       " '2016-07-04',\n",
       " '2016-07-04',\n",
       " '2016-07-04',\n",
       " '2016-07-04',\n",
       " '2016-07-04',\n",
       " '2016-07-04',\n",
       " '2016-07-05',\n",
       " '2016-07-05',\n",
       " '2016-07-05',\n",
       " '2016-07-05',\n",
       " '2016-07-05',\n",
       " '2016-07-05',\n",
       " '2016-07-05',\n",
       " '2016-07-05',\n",
       " '2016-07-06',\n",
       " '2016-07-06',\n",
       " '2016-07-06',\n",
       " '2016-07-06',\n",
       " '2016-07-06',\n",
       " '2016-07-06',\n",
       " '2016-07-06',\n",
       " '2016-07-06',\n",
       " '2016-07-07',\n",
       " '2016-07-07',\n",
       " '2016-07-07',\n",
       " '2016-07-07',\n",
       " '2016-07-07',\n",
       " '2016-07-07',\n",
       " '2016-07-07',\n",
       " '2016-07-07',\n",
       " '2016-07-08',\n",
       " '2016-07-08',\n",
       " '2016-07-08',\n",
       " '2016-07-08',\n",
       " '2016-07-08',\n",
       " '2016-07-08',\n",
       " '2016-07-08',\n",
       " '2016-07-08',\n",
       " '2016-07-09',\n",
       " '2016-07-09',\n",
       " '2016-07-09',\n",
       " '2016-07-09',\n",
       " '2016-07-09',\n",
       " '2016-07-09',\n",
       " '2016-07-09',\n",
       " '2016-07-09',\n",
       " '2016-07-10']"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[str(tracksDF[tracksDF['name']==stormnames[0]].time[i]).split(':')[0] for i in range(len(tracksDF[tracksDF['name']==stormnames[0]].time))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cb496656",
   "metadata": {},
   "outputs": [],
   "source": [
    "def largearea_withpres(dataset=None,invar=None,indices=None,tc_irad=None):\n",
    "    ds = xr.Dataset(\n",
    "    data_vars=dict(variable=([\"time\",\"plev\",\"lat\",\"lon\"], invar)),#mysvar[0])),\n",
    "    coords=dict(lat=([\"lat\"], dataset.lat.data),lon=([\"lon\"], dataset.lon.data),time=([\"time\"], np.linspace(0,len(indices)-1,len(indices))),\n",
    "               plev=([\"plev\"],dataset.plev.data)),\n",
    "    attrs=dict(description=\"coords with matrices\"),)\n",
    "    \n",
    "    LATN,LATS,LONE,LONW = tc_irad[0,:]\n",
    "    testsmall = ds['variable'][0,0,:,:].sel(lat=slice(LATS,LATN),lon=slice(LONE,LONW))\n",
    "    if testsmall.shape[0]<testsmall.shape[1]:\n",
    "        rgspt = int(testsmall.shape[0])\n",
    "    else:\n",
    "        rgspt = int(testsmall.shape[1])\n",
    "    rgspt=40\n",
    "    var_out=np.zeros((len(indices),len(dataset.plev.data),rgspt,rgspt))\n",
    "    del testsmall\n",
    "    \n",
    "    for it in range(len(indices)):\n",
    "        latn, lats, lone, lonw = tc_irad[it,:]\n",
    "        for ip in range(len(dm2.plev.data)):\n",
    "            try:\n",
    "                var_out[it,ip,:,:]=ds['variable'][it,ip,:,:].sel(lat=slice(lats,latn),lon=slice(lone,lonw))\n",
    "            except:\n",
    "                var_out[it,ip,:,:]=ds['variable'][it,ip,:,:].sel(lat=slice(lats,latn),lon=slice(lone,lonw))[0:rgspt,0:rgspt]\n",
    "    return var_out  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5928a97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_indices(TCtrack=None,ERA5date=None,ERA5hour=None):\n",
    "    allindices = []\n",
    "    for timeidx in range(len(TCtrack)):#len(track['time'])):\n",
    "        datetrack,hourtrack = TCtrack['time'][timeidx].split(':')[0],TCtrack['time'][timeidx].split(':')[1][0:2]\n",
    "        ####################################################################################################\n",
    "        # Find the indices in ERA5 data with the same date as track\n",
    "        ####################################################################################################\n",
    "        dateind = []\n",
    "        for ind,obj in enumerate(ERA5date):\n",
    "            if obj==datetrack:\n",
    "                dateind.append(ind)\n",
    "        del ind,obj\n",
    "        hourind = []\n",
    "        hourextract = ERA5hour[int(np.min(np.asarray(dateind))):int(np.max(np.asarray(dateind)))+1]\n",
    "        for ind,obj in enumerate(hourextract):\n",
    "            if obj==hourtrack:            \n",
    "                hourind.append(ind)\n",
    "        allindices.append((int(np.min(np.asarray(dateind))),int(hourind[0])))\n",
    "    return allindices\n",
    "\n",
    "def extract_var(dataset=None,var='var138',indices=None):\n",
    "    extractedvar = []\n",
    "    for i in (range(len(indices))):\n",
    "        realindex = indices[i][0]+indices[i][1]\n",
    "        extractedvar.append(dataset[var][int(realindex),...].data)\n",
    "    return np.asarray(extractedvar)\n",
    "\n",
    "def smallarea(dataset=None,invar=None,indices=None,tc_irad=None):\n",
    "    if len(invar.shape) != 3:\n",
    "        invar = np.squeeze(invar)\n",
    "    ds = xr.Dataset(\n",
    "    data_vars=dict(variable=([\"time\",\"lat\",\"lon\"], invar)),#mysvar[0])),\n",
    "    coords=dict(lat=([\"lat\"], dataset.lat.data),lon=([\"lon\"], dataset.lon.data),time=([\"time\"], np.linspace(0,len(indices)-1,len(indices)))),\n",
    "    attrs=dict(description=\"coords with matrices\"),)\n",
    "    \n",
    "    LATN,LATS,LONE,LONW = tc_irad[0,:]\n",
    "    testsmall = ds['variable'][0,:,:].sel(lat=slice(LATS,LATN),lon=slice(LONE,LONW))\n",
    "    if testsmall.shape[0]<testsmall.shape[1]:\n",
    "        rgspt = int(testsmall.shape[0])\n",
    "    else:\n",
    "        rgspt = int(testsmall.shape[1])\n",
    "    rgspt=40\n",
    "    var_out=np.zeros((len(indices),rgspt,rgspt))\n",
    "    del testsmall\n",
    "    \n",
    "    for it in range(len(indices)):\n",
    "        latn, lats, lone, lonw = tc_irad[it,:]\n",
    "        try:\n",
    "            var_out[it,:,:]=ds['variable'][it,:,:].sel(lat=slice(lats,latn),lon=slice(lone,lonw))\n",
    "        except:\n",
    "            var_out[it,:,:]=ds['variable'][it,:,:].sel(lat=slice(lats,latn),lon=slice(lone,lonw))[0:rgspt,0:rgspt]\n",
    "    return var_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b241f5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for dm1 files functions\n",
    "def make_timeseries_step1(TCname=None,era5_date=None,era5_hour=None):\n",
    "    track=tracksDF[tracksDF['name']==TCname].reset_index()\n",
    "    lon1=track['lon'].to_numpy()\n",
    "    lat1=track['lat'].to_numpy()\n",
    "    pos = np.stack((lat1, lon1), axis=1)\n",
    "    ###########################################################################\n",
    "    indices_store = output_indices(track,era5_date,era5_hour)\n",
    "    ###########################################################################\n",
    "    tc_irad=np.empty((len(indices_store),4))\n",
    "    tc_irad[:,0] = pos[:,0]-5\n",
    "    tc_irad[:,1] = pos[:,0]+5\n",
    "    tc_irad[:,2] = pos[:,1]-5\n",
    "    tc_irad[:,3] = pos[:,1]+5\n",
    "    return pos,indices_store,tc_irad\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b318d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readyear_automatic(year=None):\n",
    "    dm2 = xr.open_dataset(datapath+'/mslp/mslp_'+str(year)+'.nc')\n",
    "    #tracklist = sorted(glob.glob('/work/FAC/FGSE/IDYST/tbeucler/default/saranya/causal/besttracks/nio/*_'+str(year)+'*'))\n",
    "    era5_date = [str(dm2.time[i].data).split('T')[0] for i in range(len(dm2.time))]\n",
    "    era5_hour = [str(dm2.time[i].data).split('T')[1][0:2] for i in range(len(dm2.time))]\n",
    "    return dm2,era5_date,era5_hour\n",
    "\n",
    "dm2,era5_date,era5_hour = readyear_automatic(2014)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bcb954bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f29e9908ea7146fa8ce0e9ba6feb6589",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TCslp_ts = []\n",
    "for TCname in tqdm(stormnames):\n",
    "    ###########################################################################\n",
    "    pos,indices_store,tc_irad = make_timeseries_step1(TCname=TCname,era5_date=era5_date,era5_hour=era5_hour)\n",
    "    ###########################################################################\n",
    "    mysvar = [extract_var(dataset=dm2,var=obj,indices=indices_store) for obj in (list(dm2.keys()))]\n",
    "    \n",
    "    ################################################################################################\n",
    "    \n",
    "    smallsvarout = [smallarea(dm2,mysvar[i],indices_store,tc_irad) for i in (range(len(mysvar)))]\n",
    "    \n",
    "    svarname = ['mslp']\n",
    "    svardict = {varnameobj:varobj for (varnameobj,varobj) in zip(svarname,smallsvarout)}\n",
    "    \n",
    "    ##################################################################################################\n",
    "    #############################################################################################\n",
    "    tsdict = {}\n",
    "    for ind,obj in (enumerate(svarname)):\n",
    "        tslist = [svardict[svarname[ind]][i,...].flatten() for i in range(len(indices_store))]\n",
    "        tsdict[svarname[ind]] = [np.nanmin(obj) for obj in tslist]\n",
    "    #############################################################################################\n",
    "    TCslp_ts.append(tsdict)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0a1bfbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "storeTCdicts = {}\n",
    "for ind in range(len(TCslp_ts)):\n",
    "    storeTCdicts[stormnames[ind]] = pd.DataFrame.from_dict(TCslp_ts[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b18eb3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind,obj in enumerate(stormnames):\n",
    "    storeTCdicts[obj].to_csv(output+'2014_pmin_wpac_'+str(obj)+'.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ecda773-65d2-4018-8414-d03fc0a5df18",
   "metadata": {},
   "source": [
    "10m Wind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "1f8081dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readyear_automatic(year=None):\n",
    "    dm2 = xr.open_dataset(datapath+'/wind10/wind10_'+str(year)+'.nc')\n",
    "    #tracklist = sorted(glob.glob('/work/FAC/FGSE/IDYST/tbeucler/default/saranya/causal/besttracks/nio/*_'+str(year)+'*'))\n",
    "    era5_date = [str(dm2.time[i].data).split('T')[0] for i in range(len(dm2.time))]\n",
    "    era5_hour = [str(dm2.time[i].data).split('T')[1][0:2] for i in range(len(dm2.time))]\n",
    "    return dm2,era5_date,era5_hour\n",
    "\n",
    "dm2,era5_date,era5_hour = readyear_automatic(2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "eabb96fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a9bd17f15724decba636bb30aa6c0eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TCws10_ts = []\n",
    "for TCname in tqdm(stormnames):\n",
    "    ###########################################################################\n",
    "    pos,indices_store,tc_irad = make_timeseries_step1(TCname=TCname,era5_date=era5_date,era5_hour=era5_hour)\n",
    "    ###########################################################################\n",
    "    mysvar = [extract_var(dataset=dm2,var=obj,indices=indices_store) for obj in (list(dm2.keys()))]\n",
    "    \n",
    "    ################################################################################################\n",
    "    smallsvarout = [smallarea(dm2,mysvar[i],indices_store,tc_irad) for i in (range(len(mysvar)))]\n",
    "    \n",
    "    svarname = ['wind10']\n",
    "    svardict = {varnameobj:varobj for (varnameobj,varobj) in zip(svarname,smallsvarout)}\n",
    "    \n",
    "    ##################################################################################################\n",
    "    #############################################################################################\n",
    "    tsdict = {}\n",
    "    for ind,obj in (enumerate(svarname)):\n",
    "        tslist = [svardict[svarname[ind]][i,...].flatten() for i in range(len(indices_store))]\n",
    "        tsdict[svarname[ind]] = [np.nanmax(obj) for obj in tslist]\n",
    "    #############################################################################################\n",
    "    TCws10_ts.append(tsdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "a80456ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "storeTCdicts = {}\n",
    "for ind in range(len(TCws10_ts)):\n",
    "    storeTCdicts[stormnames[ind]] = pd.DataFrame.from_dict(TCws10_ts[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "e0681fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind,obj in enumerate(stormnames):\n",
    "    storeTCdicts[obj].to_csv(output+'2016_wmax_wpac_'+str(obj)+'.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc71a9e8",
   "metadata": {},
   "source": [
    "script ends here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
